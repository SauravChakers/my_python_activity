{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d633f46d",
   "metadata": {},
   "source": [
    "# DA301 Week 2: Predicting outcomes using classification & clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492f6e8",
   "metadata": {},
   "source": [
    "## 2.1.3 Worked example I: Checking assumptions in binary logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1df14",
   "metadata": {},
   "source": [
    "Logistic regression is used in statistical software to determine, predict, and understand the probability of the occurrence of an event. It does this by fitting data to a logit function between a dependent and one or more independent variables by employing probabilities.\n",
    "\n",
    "In this worked example, we will practise using binary logistic regression (BLR). You’ll apply a BLR model that’s based on binary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949ea9c",
   "metadata": {},
   "source": [
    "### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the provided CSV file/data set.\n",
    "df = pd.read_csv('customer_data.csv') \n",
    "\n",
    "# Print the table.\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b99c3b",
   "metadata": {},
   "source": [
    "### Determine the data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data types of columns.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aae9ea",
   "metadata": {},
   "source": [
    "### Determine the shape of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96425ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the shape of the data set.\n",
    "df.shape  \n",
    "\n",
    "# We should be able to perform BLR on a data set this size.\n",
    "# Recall BLR requires large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05986c70",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f733f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine missing values, column names, shape of data set, and data type:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29afd5",
   "metadata": {},
   "source": [
    "Assumptions 1, 2 & 6 are met for BLR\n",
    "\n",
    "The first logistic regression assumption to be met is that the output would be binary. The last column of the data set is named Target and consists of binary data. We've already indicated whether clients have a connection as binary so the desired outcome should be P(Y=1) as indicated in the Target column. So Assumptions 1 & 2 are met & 6 was met previously about data size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4ffe9",
   "metadata": {},
   "source": [
    "## 2.1.4 Worked example II: Checking for meaningful variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fd5c7",
   "metadata": {},
   "source": [
    "For this assumption to be true, we need to investigate each of the columns and determine whether they are meaningful and should be included. In short, if the variable contributes to the binary outcome, it needs to be included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2677109",
   "metadata": {},
   "source": [
    "### Determine the object containing counts of unique values\n",
    "The education column (Edu) in the DataFrame consists of strings. Before we can create dummy variables, we need to convert the strings into single words that will be easier to analyse than strings of variable lengths. For this worked example, we will only update the details of the education column.\n",
    "\n",
    "We know we can use the value_counts() function to determine the count per variable; Python will then return the name of each unique variable and the number of them in the specified column. This helps data analysts limit the number of spelling errors when specifying how to update the details (i.e. the variables) of the column. To determine the values within the Edu column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744717e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the DataFrame column & add/determine the values.\n",
    "df['Edu'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8748085",
   "metadata": {},
   "source": [
    "Some of the categories have . in their name. We need to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de3af9",
   "metadata": {},
   "source": [
    "### Update the categories in the Edu Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists: one with initial and one with new values.\n",
    "intial_vals = ['illiterate', 'unknown', 'basic', 'high', 'university', 'professional']\n",
    "new_vals = ['other', 'other', 'pre-school', 'high-school', 'uni', 'masters']\n",
    "\n",
    "# Create a for loop to replace the values.\n",
    "for old_val, new_val in zip(intial_vals, new_vals):\n",
    "    df.loc[df['Edu'].str.contains(old_val),'Edu' ] = new_val\n",
    "\n",
    "# Display all the unique values/check changes.\n",
    "df['Edu'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0662f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Edu'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6131b",
   "metadata": {},
   "source": [
    "### Convert strings into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea4fde",
   "metadata": {},
   "source": [
    "We need to convert strings to a single value for ease of data analysis. The sklearn library has a class called LabelEncoder that can convert values within a column to a number. Therefore, the categorical values become understandable numbers for our machine learning (ML) model. For example, we can transform Poor, Good, Very Good, and Excellent to 0, 1, 2, and 3. Important to remember is that the Label Encoder will order values alphabetically.\n",
    "\n",
    "Another option is to create dummy variables with the pd.get_dummies() function. The dummies variable function creates a new column for each value, resulting in a bigger DataFrame. Keeping the DataFrame smaller has a positive impact on the performance of the model, especially when you work with big data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules, classes and packages.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "\n",
    "# Create a class and write a user defined function.\n",
    "class MyLabelEncoder(LabelEncoder):\n",
    "    \n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "\n",
    "# View the output.\n",
    "df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fa184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next replace all unique values in the columns with numbers.\n",
    "# Order lists of the values for each column containing strings.\n",
    "Edu_order = ['other', 'pre-school', 'high-school', 'uni', 'masters']\n",
    "House_order = ['no', 'unknown', 'yes']\n",
    "Loan_order = ['no', 'unknown', 'yes']\n",
    "Month_order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct',\n",
    "               'nov', 'dec']\n",
    "DOW_order = ['mon', 'tue', 'wed', 'thu', 'fri']\n",
    "Last_out_order = ['nonexistent', 'failure', 'success']\n",
    "\n",
    "# List of values to transform into numbers even though the values are not ordered.\n",
    "Occupation_list = ['unemployed', 'unknown', 'student', 'blue-collar',\n",
    "                   'technician', 'housemaid', 'admin.','retired',\n",
    "                   'self-employed', 'entrepreneur', 'management', 'services']\n",
    "Status_list = ['unknown', 'single', 'divorced', 'married']\n",
    "Comm_list = ['cellular', 'telephone']\n",
    "\n",
    "# Create a list containing all of the list of values.\n",
    "Encoding_list = [Occupation_list, Status_list, Edu_order, House_order,\n",
    "                 Loan_order, Comm_list, Month_order, DOW_order, Last_out_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick non-numerical columns.\n",
    "object_cols = df.select_dtypes(include= 'object').columns\n",
    "\n",
    "#Transform string values to number with our LabelEncoder function.\n",
    "for idx in range(len(object_cols)): \n",
    "    \n",
    "    le = MyLabelEncoder()\n",
    "    le.fit(Encoding_list[idx])\n",
    "    df[object_cols[idx]] = le.transform(df[object_cols[idx]])\n",
    "    \n",
    "# View the DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d6d9b",
   "metadata": {},
   "source": [
    "### Balance the data\n",
    "\n",
    "It’s important to determine whether the data is balanced in the Target column before we can create a BLR. An unbalanced data set is when the target variable has more observations in one specific class than the others. \n",
    "\n",
    "If a model is trained on an unbalanced data set, it will return poor results. For example, inaccurately predicting a class or classifying unseen observations. Therefore, unbalanced data will affect the estimate of the model intercept and can create skewed predicted probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df42ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if values in a column are balanced.\n",
    "df['Target'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e95fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create a visualisation\n",
    "# Create a plot with Seaborn.\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "ax = sns.countplot(x='Target', data=df)\n",
    "ax.set_title('Target Imbalance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdae89",
   "metadata": {},
   "source": [
    "The data is not balanced as there are many more 0 values than 1. Before you can balance the data, you need to import a few libraries. \n",
    "\n",
    "The new libraries you will need to install are:\n",
    "\n",
    "imblearn: handles unbalanced data and relies on the scikit-learn library\n",
    "scipy: for optimisation, linear algebra, integration\n",
    "scikit-learn: simple and efficient tools for predictive data analysis\n",
    "SMOTE: an oversampling technique that creates new samples from existing data.\n",
    "\n",
    "Next, you need to balance the Target variable with the SMOTE() function. To balance the Target variable with the SMOTE() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages:\n",
    "import statsmodels.api as sm   \n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Set the variables:\n",
    "X = df.drop('Target', axis = 1)\n",
    "y = df['Target']\n",
    "\n",
    "# Apply SMOTE as the target variable is not balanced.\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Specify the new data sets.\n",
    "os_data_X, os_data_y = os.fit_resample(X_train, y_train)  \n",
    "\n",
    "# Create two DataFrames for X and one for y:\n",
    "os_data_X = pd.DataFrame(data = os_data_X, columns = X.columns) \n",
    "\n",
    "os_data_y = pd.DataFrame(data = os_data_y, columns = ['Target'])\n",
    "\n",
    "# View DataFrame.\n",
    "print(os_data_X.head())\n",
    "os_data_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef32e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's determine if the balancing worked by using the value_counts() function:\n",
    "# Determine if values in a column are balanced by counting the values.\n",
    "os_data_y['Target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualisation now.\n",
    "sns.set_theme(style ='darkgrid')\n",
    "ax = sns.countplot(x ='Target', data = os_data_y)\n",
    "ax.set_title(\"New Balanced Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdc4e0",
   "metadata": {},
   "source": [
    "Notice how each data set contains exactly the same number of zeros and ones. From this, we can conclude the data sets for our analysis contain meaningful variables that are now balanced (Assumption 3). Remember that an unbalanced data set will return poor results, and we needed to use the SMOTE technique to balance the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac3ced",
   "metadata": {},
   "source": [
    "There are still two logistic regression assumptions we need to check. They are:\n",
    "\n",
    "Assumption 4: The independent variables () should be independent of each other to limit/eliminate multicollinearity.\n",
    "Assumption 5: The independent variables () are linearly related to the log odds.\n",
    "\n",
    "Let’s investigate how to test these two assumptions and how to build and fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fa9e6",
   "metadata": {},
   "source": [
    "### Variance Inflation Factor - testing for collinearity\n",
    "\n",
    "Apply VIF to satisfy Assumption 4.\n",
    "\n",
    "Note that a VIF < 10 indicates limited to no correlation between independent variables. The closer the VIF is to 1, the less correlation between independent variables. However, a VIF > 10 indicates a multicollinearity problem due to strong correlations. Some experts and researchers in the field prefer a more conservative threshold of 5 or 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the VIF package.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a VIF dataframe.\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = df.columns\n",
    "  \n",
    "# Calculate VIF for each feature.\n",
    "vif_data['VIF'] = [variance_inflation_factor(df.values, i)\n",
    "                          for i in range(len(df.columns))]\n",
    "\n",
    "# View the output.\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b739e1",
   "metadata": {},
   "source": [
    "The values of Duration, Campaign and Target are less than 10 (even <5) indicating no correlation between these independent variables.\n",
    "\n",
    "Since the columns Quarterly_emp and Price_idx have very high VIF values, we drop them to avoid multicollinearity between the columns and boost the performance of our logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the columns with VIF > 10 to avoid multicollinearity problems.\n",
    "df = df.drop(['Price_idx', 'Quarterly_emp'], axis = 1)\n",
    "\n",
    "# View the DataFrame.\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76008b4b",
   "metadata": {},
   "source": [
    "### Testing linearity with log odds\n",
    "\n",
    "The Box-Tidwell test can be used to explore whether the independent variables (x) are linearly related to the log odds (Assumption 5). However, the Box-Tidwell test is only applicable to continuous variables. Since we only have one continuous column left, we can do a visual check of the linearity with log odds using this column. When having multiple continuous columns or when we can’t visually see the linear relationship, it’s better to use Box-Tidwell test.  \n",
    "\n",
    "Another way to test the linearity in question is to plot the continuous independent variables (in our case the Duration column) and to look for an S-shaped curve. This can be done with the following code using the Seaborn statistical plotting library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = sns.regplot(x = 'Duration', y= 'Target', data= df,\n",
    "                  logistic= True).set_title(\"Duration Log Odds Linear Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3085a",
   "metadata": {},
   "source": [
    "### Select necessary columns for BLR\n",
    "\n",
    "Now that we have tested all the assumptions (2.1.2 Logistic regression), the next step is to select the independent variables that we think have an effect on the dependent variable. These independent variables are represented in the columns. Therefore, we will select only the necessary columns for the BLR. Once we select the variables, we just run the logit function and summarise the model efficacy by checking the p-values and R-squared value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the necessary columns for BLR\n",
    "# Name the new DataFrame and specify all the columns for BLR:\n",
    "nec_cols = df.drop('Target', axis = 1).columns\n",
    "\n",
    "# Set the independent variable.\n",
    "X = os_data_X[nec_cols]  \n",
    "\n",
    "# Set the dependent variable.\n",
    "y = os_data_y['Target']  \n",
    "\n",
    "# Set the logit() to accept y and x as parameters and return the logit object:\n",
    "logit_model=sm.Logit(y, X)\n",
    "\n",
    "# Indicate result = logit_model.fit() function.\n",
    "result = logit_model.fit()  \n",
    "\n",
    "# Print the results.\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e365aa",
   "metadata": {},
   "source": [
    "### Determine the accuracy of the model\n",
    "\n",
    "To check if the BLR model is working and accurate, we need to first check if the LogisticRegression() function is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Split X and y data sets into ‘train’ and ‘test’ in a 30:70 ratio:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Set LogisticRegression() to logreg.\n",
    "logreg = LogisticRegression(max_iter=5000) \n",
    "\n",
    "# Fit the X_train and y_train data sets to logreg. \n",
    "logreg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9911ab5",
   "metadata": {},
   "source": [
    "The output indicates that the LogisticRegression() function is active! So, let’s proceed to determine the accuracy of the BLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine BLR model’s accuracy:\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'\\\n",
    "      .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562834f",
   "metadata": {},
   "source": [
    "To further test the model’s accuracy, we can also employ a confusion matrix to evaluate the accuracy of the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4eaa2",
   "metadata": {},
   "source": [
    "### Create a confusion matrix\n",
    "\n",
    "A confusion matrix is a tabular summary of prediction results. Think of a confusion matrix as a specific table layout that allows us to capture the performance of a classification algorithm in a simple visual manner. A confusion matrix is not a metric to evaluate a model. Instead, it provides insights into the predictions. It’s important to learn how to create a confusion matrix because it will help you to understand other classification metrics such as precision and recall.\n",
    "\n",
    "It’s called a ‘confusion matrix’ because this cross-tabulation helps us assess if our chosen procedure is confusing two classes (i.e. frequently mislabelling one as another). Consider the following:\n",
    "\n",
    "- each row of the matrix represents the actual number of observations in a given class\n",
    "- each column represents the predicted number of observations in a given class (or vice versa)\n",
    "- each cell in the table thus reports the number of observations by actual and predicted class.\n",
    "\n",
    "A confusion matrix goes deeper than classification accuracy by showing the correct and incorrect (i.e. true or false) predictions of each class. In the case of a binary classification task, a confusion matrix is a 2 x 2 matrix. If there are three different classes, it would be a 3 x 3 matrix, and so on. \n",
    "\n",
    "Now that we have learned about these elements, let’s create a confusion matrix based on the actual and predicted dependent variable values (y_test and y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fe7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix to test classification accuracy in BLR:\n",
    "# Import the necessary package to create the confusion matrix. \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "\n",
    "# Indicate the confusion matrix needs to be created.\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "# Plot the confusion_matrix.\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef923c",
   "metadata": {},
   "source": [
    "To conclude this worked example, let’s calculate the precision (positive predictive value), recall (sensitivity, or true positive rate), f1-score (test accuracy) and support of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary package.\n",
    "from sklearn.metrics import classification_report  \n",
    "\n",
    "# Print a report on the model's accuracy.\n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504163dc",
   "metadata": {},
   "source": [
    "The high precision scores indicate that the model is accurate. This is an important metric in this case, as we’ll need to use the model to select the most appropriate customers for the new project. In other situations, accuracy might be the most important criterion, because it is a broader measure of how many classifications are correct. In some cases, recall might be important, because we might want to know how many instances of selecting a customer were, in fact, correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8ff0d",
   "metadata": {},
   "source": [
    "## 2.1.6 Practical activity: Building a BLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab787b7f",
   "metadata": {},
   "source": [
    "### Basic setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e72a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set.\n",
    "df = pd.read_csv('breast_cancer_data.csv', \n",
    "                 index_col='id')\n",
    "\n",
    "# View the DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if there are any null values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the descriptive statistics.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cde978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All null values will be dropped.\n",
    "df.drop(labels='Unnamed: 32', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the count of values.\n",
    "# df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the data set is balanced.\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b77520",
   "metadata": {},
   "source": [
    "### Create the BLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Specify the columns.\n",
    "target_col = 'diagnosis'\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# Set the variables.\n",
    "X =  df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Create the train and test data sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify and fit the model.\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cad64a",
   "metadata": {},
   "source": [
    "### Calculate accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predicted labels and predicted probabilities on the test set.\n",
    "# Predict test class.\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Predict test probability.\n",
    "y_pp = logreg_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix for your classifier's performance on the test set.\n",
    "con_mat = confusion_matrix(y_test, y_pred, labels=['M', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cancer based on some kind of detection measure, like we did before.\n",
    "confusion = pd.DataFrame(con_mat, index=['predicted_cancer','predicted_healthy'],\n",
    "                         columns=['is_cancer', 'is_healthy'])\n",
    "\n",
    "# View the output.\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use float to perform true division, not integer division.\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f14ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82effc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an accuracy report.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6f3bf",
   "metadata": {},
   "source": [
    "## 2.1.7 Worked example: Building an MLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf798f",
   "metadata": {},
   "source": [
    "Remember that there are three types of logistic regression: binary, multinomial, and ordinal. You’ve already built a BLR model consisting of binary data. Here, we’ll investigate multinomial logistic regression (MLR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551ced0",
   "metadata": {},
   "source": [
    "### Multinomial logistic regression\n",
    "\n",
    " MLR is similar to the BLR model you worked on earlier, but MLR can predict the probabilities of different possible outcomes of a categorical dependent variable conditional on a set of independent variables. The independent variable can be real-valued, categorical-valued, or binary-valued. For example, while BLR can predict binary outcomes (e.g. yes or no, 1 or 0), the MLR can predict one out of  possible outcomes, where  can be any integer greater than 1.\n",
    " \n",
    "MLR explains the relationship between one nominal dependent variable and one or more independent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0525f",
   "metadata": {},
   "source": [
    "#### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages: Pandas, NumPy, SciPy, Sklearn, StatsModels.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Upload the CSV file.\n",
    "oysters = pd.read_csv('oysters.csv')  \n",
    "\n",
    "# Print the columns.\n",
    "oysters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame.\n",
    "oysters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the value_counts() method, and \n",
    "# assign the results to a new DataFrame.\n",
    "oysters_sex=oysters['sex'].value_counts()\n",
    "\n",
    "# Print the contents.\n",
    "print(oysters_sex)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3040d1",
   "metadata": {},
   "source": [
    "The next steps will be to separate the dependent variable from the independent variables, build the model, create the equation, and test the model’s accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b088912",
   "metadata": {},
   "source": [
    "#### Set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the independent and dependent variables:\n",
    "# Set the independent variable.  \n",
    "X = oysters.drop(['sex'], axis=1) \n",
    "# Set the dependent variable. \n",
    "y = oysters['sex']   \n",
    "\n",
    "# Print to check sex column was dropped.\n",
    "print(list(X.columns.values))  \n",
    "\n",
    "# Specify the train and test data sets and \n",
    "# use 30% as the 'test_size' and a random_state of one.\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.30, random_state = 1, stratify=y) \n",
    "\n",
    "# Print the shape of all the train and tests sets.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31652869",
   "metadata": {},
   "source": [
    "The output is correct because 30% of 9,484 values is 2,845.2 (2,846 rounded up as you cannot get a partial oyster). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aaa4dd",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebef8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MinMaxScaler to normalise the data.\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "\n",
    "# Create a function and set values.\n",
    "scaler = MinMaxScaler(feature_range = (0,1))  \n",
    "\n",
    "# Add the X_train data set to the 'scaler' function.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Specify X_train data set.\n",
    "X_train = scaler.transform(X_train) \n",
    "# Specify X_test data set. \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e220c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLR model and  set predictions and parameters.\n",
    "MLR = LogisticRegression(random_state=0, \n",
    "                         multi_class='multinomial', \n",
    "                         penalty='none', \n",
    "                         solver='newton-cg').fit(X_train, y_train)\n",
    "# Set the predictions equal to the ‘MLR’ function and \n",
    "# specify the DataFrame.\n",
    "preds = MLR.predict(X_test) \n",
    "\n",
    "# Set the parameters equal to the DataFrame and \n",
    "# add the ‘get_params’ function. \n",
    "params = MLR.get_params() \n",
    "\n",
    "# Print the parameters.\n",
    "print(params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b86e19",
   "metadata": {},
   "source": [
    "Next, we need to evaluate the MLR intercept and coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9119c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept: \\n\", MLR.intercept_)\n",
    "print(\"Coefficients: \\n\", MLR.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdc8df",
   "metadata": {},
   "source": [
    "#### Create the linear equation from the logit model\n",
    "\n",
    "In this example, we will use a different method to create a linear equation.\n",
    "\n",
    "You’ll use the MNLogit(statsmodels) function, which is similar to the logistic regression (sklearn.linear_model) we employed earlier. However, it’s from another package. Python has different functions that can be employed to get similar results. It’s important to take note of these similarities as some team members or stakeholders might use a different approach than you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the model and [2] Set model to the function.\n",
    "logit_model=sm.MNLogit(y_train,sm.add_constant(X_train))\n",
    "logit_model\n",
    "\n",
    "# Specify how the function returns the results.\n",
    "result=logit_model.fit()  \n",
    "\n",
    "# Print the report as a result.summary() function: \n",
    "print(\"Summary for Sex:I/M :\\n \", result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016a2c5",
   "metadata": {},
   "source": [
    "#### Determine the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print a confusion matrix:\n",
    "# y_test as the first argument and the predictions as the second argument. \n",
    "confusion_matrix(y_test, preds)\n",
    "\n",
    "# Transform confusion matrix into an array:\n",
    "cmatrix = np.array(confusion_matrix(y_test, preds))\n",
    "\n",
    "# Create the DataFrame from cmatrix array. \n",
    "pd.DataFrame(cmatrix, index=['female','infant', 'male'],\n",
    "columns=['predicted_female', 'predicted_infant', 'predicted_male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine accuracy statistics:\n",
    "print('Accuracy score:', metrics.accuracy_score(y_test, preds))  \n",
    "\n",
    "# Create classification report:\n",
    "class_report=classification_report(y_test, preds)\n",
    "\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e42134",
   "metadata": {},
   "source": [
    "The accuracy of the model is 55%, which is not very accurate and therefore not useful as a predictive model. It seems that there is a 48% chance of success to indicate females by employing size as a variable. Therefore, as breeding programmes are very expensive and time-consuming, it might not be the best way to proceed. While inaccuracy seems to be a negative indicator, in fact, we have saved the oyster breeders a lot of wasted time and money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b0af6",
   "metadata": {},
   "source": [
    "#### Visualise the model\n",
    "\n",
    "You might need to create a visualisation of the outputs (confusion matrix) from the MLR model you created, for reporting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7536c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib to create a visualisation.\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Define confusion matrix.\n",
    "cm = confusion_matrix(y_test, preds)  \n",
    "\n",
    "# Create visualisation for the MLR:\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1, 2), ticklabels=('female', 'infant', 'male'))\n",
    "ax.yaxis.set(ticks=(0, 1, 2), ticklabels=('female', 'infant', 'male'))\n",
    "\n",
    "# ax.set_ylim(1.5, -0.5)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white', size='xx-large')\n",
    "        \n",
    "# Sets the labels.\n",
    "plt.xlabel('Predictions', fontsize=16)\n",
    "plt.ylabel('Actuals', fontsize=16)\n",
    "plt.title('Confusion Matrix', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd4439",
   "metadata": {},
   "source": [
    "The oyster research station needed to accurately determine the sex of mature oysters based on size measurements. Using multinomial logistic regression (MLR), we can now see from the output (which is essentially a confusion matrix) that our model correctly classified 314 females as females while it incorrectly classified 160 cases as infants and 460 cases as males. Similarly, 57 cases were incorrectly identified as infants while 676 cases were accurately classified as infants. But there were 110 cases that were incorrectly identified as males. Finally, there were 304 and 244 cases where the model incorrectly classified the males as females and infants respectively. But it also identified 521 accurate cases of male."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bbe73",
   "metadata": {},
   "source": [
    "## 2.1.10 Worked example: Building a Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97194c",
   "metadata": {},
   "source": [
    "### Prepare Workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608877d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import all the necessary packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm \n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read the data file with Pandas.\n",
    "df = pd.read_csv('customer_data.csv')  \n",
    "\n",
    "# Sense-check the data.\n",
    "df.info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357fe27",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "As with the BLR we need to update the Edu column to eliminate any periods. The same code snippet and explanation applies to the SVM model as with the BLR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update all the details of the education column:\n",
    "df.loc[df['Edu'].str.contains('basic'),'Edu' ] = 'pre-school'\n",
    "df.loc[df['Edu'].str.contains('university'),'Edu' ] = 'uni'\n",
    "df.loc[df['Edu'].str.contains('high'),'Edu' ] = 'high-school'\n",
    "df.loc[df['Edu'].str.contains('professional') ,'Edu'] = 'masters'\n",
    "df.loc[df['Edu'].str.contains('illiterate'),'Edu' ] = 'other'\n",
    "df.loc[df['Edu'].str.contains('unknown'),'Edu' ] = 'other'\n",
    "\n",
    "# Display all the unique values/check changes.\n",
    "df['Edu'].unique()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce501a9",
   "metadata": {},
   "source": [
    "### Create dummy variable\n",
    "The next step is to create the dummy variables (to account for the effects of one or more nominal-scale variables on the dependent variable). The process, explanations and code snippet are the same as with the BLR model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to dummy variables:\n",
    "cat_vars=['Occupation', 'Status', 'Edu', 'House',\n",
    "          'Loan', 'Comm', 'Month', 'DOW', 'Last_out']\n",
    "\n",
    "# Specify what needs to apply to all the variables.\n",
    "for var in cat_vars: \n",
    "    # Specify details of the categorical list.\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var) \n",
    "    # Indicate the joining of the DataFrames.\n",
    "    df1=df.join(cat_list) \n",
    "    # Set old the DataFrame with new df with dummy values.\n",
    "    df=df1 \n",
    "    \n",
    "    cat_vars=['Occupation','Status', 'Edu', 'House', 'Loan',\n",
    "              'Comm', 'Month','DOW','Last_out']\n",
    "    \n",
    "# Set the temporary DataFrame and add values.\n",
    "df_vars=df.columns.values.tolist() \n",
    "# Indicate what columns are kept.\n",
    "to_keep=[i for i in df_vars if i not in cat_vars] \n",
    "    \n",
    "# Define a new DataFrame.\n",
    "df_fin=df[to_keep] \n",
    "\n",
    "# Print the column names.\n",
    "df_fin.columns.values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee3bb3",
   "metadata": {},
   "source": [
    "### Balance the data\n",
    "\n",
    "The SVM is not a regression model. Therefore, you don’t have to specify the variables (X and Y) as we did with the BLR model. However, you still have to apply the SMOTE process to balance the data. Before you apply the SMOTE process, identify the necessary columns that should be part of the SVM model. It will be the same columns as with the BLR model.\n",
    "\n",
    "The same code snippet and explanations apply as the previous practical activity, only the order differs. With the BLR model, we first applied the SMOTE process and then selected the necessary columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to use as df_fin and replace missing values with zero:\n",
    "df_fin = df_fin.fillna(0)\n",
    "\n",
    "# Specify only the necessary columns for BLR: \n",
    "nec_cols = [ 'Status_divorced', 'Status_married',\n",
    "            'Status_single', 'Status_unknown', \n",
    "            'Edu_high-school', 'Edu_masters', \n",
    "            'Edu_other', 'Edu_pre-school', \n",
    "            'Edu_uni', 'House_no', 'House_unknown',\n",
    "            'House_yes', 'Loan_no', 'Loan_unknown', \n",
    "            'Loan_yes', 'DOW_fri', 'DOW_mon']\n",
    "\n",
    "# Set the variables.\n",
    "X = df_fin[nec_cols]  \n",
    "y = df_fin.loc[:, df_fin.columns == 'Target']   \n",
    "\n",
    "# Create a new DataFrame and \n",
    "# apply SMOTE as the target variable is not balanced.\n",
    "os = SMOTE(random_state=0) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Specify column values.\n",
    "columns = X_train.columns   \n",
    "\n",
    "# Specify the new data sets.   \n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train) \n",
    "\n",
    "# Create two DataFrames for X and one for y:\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Target'])\n",
    "\n",
    "# Print the DataFrame.\n",
    "print(\"length of oversampled data is \",len(os_data_X)) \n",
    "\n",
    "os_data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e598",
   "metadata": {},
   "source": [
    "#### Checking to see if data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ee899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if values in a column are balanced.\n",
    "os_data_y['Target'].value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6d65e",
   "metadata": {},
   "source": [
    "The data is balanced as there aren’t more 0 values than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bb92d",
   "metadata": {},
   "source": [
    "### Build and apply the SVM Model\n",
    "\n",
    "Next, you will build and apply the SVM model. This code snippet is different from the BLR model as it is specific to an SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35148843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages. \n",
    "from sklearn import svm  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "\n",
    "#Create an svm classifier using a linear kernel.\n",
    "clf = svm.SVC(kernel='linear', gamma='scale')  \n",
    "\n",
    "# Train the model using the training sets.\n",
    "clf.fit(os_data_X, os_data_y)  \n",
    "\n",
    "# Predict the response for the test data set.\n",
    "y_pred = clf.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b03a2f",
   "metadata": {},
   "source": [
    "### Determine the accuracy of the model\n",
    "\n",
    "Finally, the model was built and fitted to the data set. Let’s prepare the confusion matrix and accuracy report to determine how the SVM and BLR models compare. However, there is also another way to calculate the accuracy, precision, and recall of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import the scikit-learn metrics module for an accuracy calculation:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix.\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "\n",
    "# Specify model accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Specify model precision: what percentage of \n",
    "# positive tuples are labelled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Specify model recall: how good is the model at \n",
    "# correctly predicting positive classes?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b28ec3",
   "metadata": {},
   "source": [
    "The confusion matrix indicates (from left to right and top to bottom) there are:\n",
    "\n",
    "7,360 true positives\n",
    "3,621 false positives\n",
    "789 false negatives\n",
    "587 true negative. \n",
    "The accuracy of the model is 64%, precision is 14% and recall is 43%.\n",
    "\n",
    "The BLR model predicted 85% fit, while the SVM predicted only 64% fit. So, which one can we trust? Next, you'll evaluate the accuracy of your BLR model by building an SVM, which will allow you to compare the two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85632239",
   "metadata": {},
   "source": [
    "## 2.1.11 Practical activity: Build and fit an SVM model\n",
    "\n",
    "In this activity, you will evaluate the accuracy of the BLR model built in the previous activity of this week. You will do this by building an SVM and comparing the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ebaaf5",
   "metadata": {},
   "source": [
    "### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce749a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd623c",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fdf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set.\n",
    "df = pd.read_csv('breast_cancer_data.csv', \n",
    "                 index_col='id')\n",
    "\n",
    "# View the DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of null values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the descriptive statistics.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caef194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All null values will be dropped.\n",
    "df.drop(labels='Unnamed: 32', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values.\n",
    "df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ce981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the data set is balanced.\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7a023",
   "metadata": {},
   "source": [
    "### Create a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Select columns.\n",
    "target_col = 'diagnosis'\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# Set the variables.\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Create the train and test data sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Create an SVM Classifier.\n",
    "clf = svm.SVC(kernel='linear', gamma='scale') \n",
    "\n",
    "# Train the model using the training sets.\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict the response for the test data set.\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542f66b",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a confusion matrix.\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# View the confusion matrix.\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary package.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the output.\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317be357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use float to perform true division, not integer division.\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f742b",
   "metadata": {},
   "source": [
    "## Demonstration: fitting a classification decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0745cb",
   "metadata": {},
   "source": [
    "### Prepare workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "# Provides classes and functions to estimate many different statistical methods.\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "# Note: Helps split data into sets to create BLR.\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: Indicates situations that aren’t necessarily exceptions.\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# Read the provided CSV file/data set.\n",
    "df = pd.read_csv('customer_data.csv')  \n",
    "\n",
    "# Print a summary of the DataFrame to sense-check it.\n",
    "df.info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925425fe",
   "metadata": {},
   "source": [
    "### Update Variables in Edu Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b2427",
   "metadata": {},
   "source": [
    "As with the BLR and SVM models, we need to update the Edu column to eliminate any periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Update all the details of the education column:\n",
    "df.loc[df['Edu'].str.contains('basic'),'Edu' ] = 'pre-school'\n",
    "df.loc[df['Edu'].str.contains('university'),'Edu' ] = 'uni'\n",
    "df.loc[df['Edu'].str.contains('high'),'Edu' ] = 'high-school'\n",
    "df.loc[df['Edu'].str.contains('professional') ,'Edu'] = 'masters'\n",
    "df.loc[df['Edu'].str.contains('illiterate'),'Edu' ] = 'other'\n",
    "df.loc[df['Edu'].str.contains('unknown'),'Edu' ] = 'other'\n",
    "\n",
    "# [2] Display all the unique values/check changes.\n",
    "df['Edu'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c1e66",
   "metadata": {},
   "source": [
    "### Create dummy variables\n",
    "\n",
    "The next step is to create the dummy variables (to account for the effects of one or more nominal-scale variables on the dependent variable). When fitting a decision tree, however, you might not need to create dummy variables, for example, if the values are already discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e91305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name new DataFrame and convert categorical variables to dummy variables:\n",
    "cat_vars=['Occupation','Status','Edu','House','Loan',\n",
    "          'Comm','Month','DOW','Last_out']\n",
    "\n",
    "# Use the for loop keyword to specify what actions to\n",
    "# apply to all the 'var' items:\n",
    "# Specify what needs to apply to all the variables.\n",
    "for var in cat_vars:  \n",
    "    # cat_list='var'+'_'+var\n",
    "    # Specify details of the categorical list.\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var)  \n",
    "    # Indicate the joining of the DataFrames.\n",
    "    df=df.join(cat_list) \n",
    "\n",
    "df_fin = df.drop(cat_vars,axis=1) \n",
    "\n",
    "# Specify the column names:\n",
    "cat_vars=['Occupation','Status','Edu','House','Loan',\n",
    "          'Comm','Month','DOW','Last_out']\n",
    "\n",
    "# Set a temporary DataFrame and add values.\n",
    "df_vars=df.columns.values.tolist()  \n",
    "\n",
    "# Indicate what columns are kept.\n",
    "to_keep=[i for i in df_vars if i not in cat_vars] \n",
    "\n",
    "# Define new DataFrame.\n",
    "df_fin=df[to_keep]  \n",
    "\n",
    "# Print the column.\n",
    "df_fin.columns.values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440cb3f",
   "metadata": {},
   "source": [
    "### Balance the data\n",
    "\n",
    "The classification decision tree is not a regression model. Therefore, we don’t have to specify the variables (X and y) as we did with the BLR model. However, for consistency in comparing the final result with the BLR and SVM models, we still have to apply the SMOTE process to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to use as df_fin and replace missing values with zero.\n",
    "df_fin = df_fin.fillna(0)  \n",
    "\n",
    "# Select necessary columns: \n",
    "nec_cols = [ 'Status_divorced', 'Status_married',\n",
    "            'Status_single', 'Status_unknown', \n",
    "            'Edu_high-school', 'Edu_masters', \n",
    "            'Edu_other', 'Edu_pre-school', \n",
    "            'Edu_uni', 'House_no', 'House_unknown',\n",
    "            'House_yes', 'Loan_no', 'Loan_unknown', \n",
    "            'Loan_yes', 'DOW_fri', 'DOW_mon']\n",
    "\n",
    "X = df_fin[nec_cols]\n",
    "y = df_fin['Target']\n",
    "\n",
    "# Create a new DataFrame and \n",
    "# apply SMOTE as the target variable is not balanced.\n",
    "os = SMOTE(random_state=0)  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Specify column values.\n",
    "columns = X_train.columns  \n",
    "# Specify the new data sets.\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)  \n",
    "\n",
    "# Create two DataFrames for X and one for y:\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Target'])\n",
    "\n",
    "# Print/check the DataFrame:\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "\n",
    "os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00dc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if data is balanced\n",
    "# Determine if values in a column are balanced.\n",
    "os_data_y['Target'].value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ccd37",
   "metadata": {},
   "source": [
    "### Build and fit the decision tree model\n",
    "\n",
    "Next, you will build and apply the classification decision tree model. This code snippet is different from the BLR and SVM models as it is specific to a classification decision tree model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DecisionTreeClassifier class from sklearn. \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "# Create a classification decision tree classifier object as dtc: \n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)\n",
    "\n",
    "# Train the decision tree classifier.\n",
    "dtc = dtc.fit(os_data_X, os_data_y) \n",
    "\n",
    "# Predict the response for the test data set.\n",
    "y_pred = dtc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a631b",
   "metadata": {},
   "source": [
    "# Determine the accuracy of the model\n",
    "\n",
    "Finally, let’s prepare the confusion matrix and accuracy report to determine how the SVM and BLR models compare. Recall a confusion matrix is a tabular summary of the prediction results that provides insights into the predictions and helps analysts understand key classification metrics .\n",
    "\n",
    "A confusion matrix can go deeper than classification accuracy by also showing correct and incorrect (i.e. true or false) predictions of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn metrics module for accuracy calculation:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use the print() function to display the confusion matrix results:\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Metrics for accuracy.\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) \n",
    "\n",
    "# Metrics for precision. \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)) \n",
    "\n",
    "# Metrics for recall.\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a866ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the following code to generate the classification report:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e7986",
   "metadata": {},
   "source": [
    "We can note the following from these results:\n",
    "\n",
    "The accuracy of the model is 72.7%, indicating the model is somewhat accurate at correctly identifying relevant customers versus irrelevant customers. (Hint: Remember that you have to use the weighted average.)\n",
    "A precision score of 14.8% is very low, which indicates that many of the selected customers did not, in fact, fit the required profile. (Hint: We have specified the customers that fit the profile as 1.)\n",
    "The recall score of 30% is relatively low, indicating that the model is incorrectly classifying many positive cases (i.e. there were 2,420 false positives, to be precise). (Hint: We have specified the customers that fit the profile as 1.)\n",
    "These scores are not necessarily a problem if the business prefers to rather identify some people who don’t fit the customer profile rather than potentially miss out on potential customers who do. \n",
    "\n",
    "How do these scores compare with the output of the BLR and SVM models? Recall the BLR model predicted a 85% fit, and the SVM predicted only a 64% fit. The result of all three tests can be tabulated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f8671",
   "metadata": {},
   "source": [
    "\n",
    "     MODEL              ACCURACY (FIT)           PRECISION           RECALL\n",
    "     \n",
    "     BLR                    85%                     85%               85%\n",
    "     SVM                    64%                     14%               43%\n",
    "     Decision Tree          72.7%                   14.8%             30.5%\n",
    "\n",
    "\n",
    "\n",
    "Summary of the test results of the binary logistic regression (BLR), support vector machine (SVM), and decision tree models\n",
    "\n",
    "So, which model is more accurate and, therefore, the one we should use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ff7e1",
   "metadata": {},
   "source": [
    "### Visualise the Model\n",
    "\n",
    "You might need to create a visualisation of the output (confusion matrix) from the classification decision tree model you created. The main reason would be for reporting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib to create a visualisation \n",
    "# and the tree package from sklearn:\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import tree\n",
    "\n",
    "# Plot the decision tree to create the visualisation:\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "tree.plot_tree(dtc, fontsize=10)\n",
    "\n",
    "# Print the plot with plt.show().\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a280a",
   "metadata": {},
   "source": [
    "You can change the number of levels of the decision tree to be displayed by adjusting the value of max_depth. Play around with this and change it to 3, 6, 10 or any number you prefer, indicating to Python how many levels to display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the levels displayed on the decision tree:\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3ca48",
   "metadata": {},
   "source": [
    "## Regression Decision Tree - Worked Example\n",
    "\n",
    "Decision trees can solve both classification or regression problems, which is why decision trees are synonymous with the umbrella term ‘CART algorithm’. You’ve just worked through an example of how to use and check the accuracy of a classification decision tree (which, recall, predicts fixed or categorical target variables). In this example, you’ll learn how to do the same with a regression decision tree model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3795a78",
   "metadata": {},
   "source": [
    "Regression trees predict continuous variables and answer questions like, ‘What predictions can be made about output Y given new input X?’ A regression decision tree uses an algorithm to fit the target value (i.e. the value you want to predict, like a stock’s value) using each of the independent variables (variables that affect the stock’s price). To do this, the available data is split at several points for each independent variable. The split, as you’ll soon see, occurs after the sum of squared errors (SSE) is calculated between the predicted and actual values. Remember that the target variables should be numeric or continuous to fit a regression decision model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40922e4b",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "Adika Wati, a data analyst from Malaysia, is employed by an online electronic retailer, Electronics Online (EO). Mr Adam Wheeler, a manager at EO, is busy compiling the annual report to be presented at a board meeting and wants to indicate whether the company performed well and how accurate the forecasts are, based on historical data. \n",
    "\n",
    "The board will likely ask what predictions can be made about the stock price given new inputs, which requires a model that outputs continuous variables. Therefore, to assist, Adika is asked to build a regression decision tree model. After building this model, he will test its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ebf0f",
   "metadata": {},
   "source": [
    "#### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries:\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "# Note: Provides classes and functions to estimate many\n",
    "# different statistical methods.\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: Indicates situations that aren’t necessarily exceptions.\n",
    "import warnings  \n",
    "# Filter out any warning messages.\n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "#Read the provided CSV file/data set.\n",
    "df = pd.read_csv('ecommerce.csv')\n",
    "\n",
    "#Print a summary of the DataFrame to sense-check it.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7b37e",
   "metadata": {},
   "source": [
    "#### Build and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify that the column Median_s \n",
    "# should be moved into a separate DataFrame.\n",
    "cols = df.columns[df.columns != 'Median_s']  \n",
    "\n",
    "# Specify ‘X’ as the independent variables \n",
    "# and ‘y’ as the dependent variable:\n",
    "X = df[cols]\n",
    "y = df['Median_s']\n",
    "\n",
    "# Split the data training and testing 30/70:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Import the ‘DecisionTreeRegressor’ class from sklearn.\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "\n",
    "# Create the ‘DecisionTreeRegressor’ class \n",
    "# (which has many parameters; input only #random_state=0):\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Fit the regressor object to the data set.\n",
    "regressor.fit(X_train,y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201ebb6",
   "metadata": {},
   "source": [
    "#### Determine the accuracy of the model\n",
    "\n",
    "Testing the accuracy of the regression decision tree model works slightly differently from the previous models you have tested. The regression decision tree model is based on statistical methods, therefore it will calculate the mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE). \n",
    "\n",
    "The MAE is average absolute error (i.e. calculate the absolute differences between each predicted value and its corresponding actual value and then take the average of these). MAE indicates, on average, how large of an (absolute) error we can expect between predicted and actual output, which makes MAE a very popular method to determine the accuracy of a regression decision tree in industry forecasts.\n",
    "\n",
    "The MSE is the average squared error (i.e. calculate the squared differences between each predicted value and its corresponding actual value, and then take the average of these); RMSE is its square root (RMSE= Sqr Rt MSE). Once calculated, you can compare the RMSE and MAE to determine whether the forecast contains large but infrequent errors. The larger the difference between them, the more inconsistent the error size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages:\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "# Predict the response for the data test.\n",
    "y_predict = regressor.predict(X_test)  \n",
    "\n",
    "# Specify to print the MAE and MSE (to evaluate the accuracy of the new model):\n",
    "print(\"Mean Absolute Error: \", metrics.mean_absolute_error(y_test, y_predict))\n",
    "print(\"Mean Squared Error: \", metrics.mean_squared_error(y_test, y_predict))\n",
    "# [3b] Calculate the RMSE.\n",
    "print(\"Root Mean Squared Error: \", \n",
    "     math.sqrt(metrics.mean_squared_error(y_test, y_predict)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24492114",
   "metadata": {},
   "source": [
    "Fantastic! The output indicates that the MAE is 3.26, the MSE is 26.4, and the RMSE is 5.14, rounded to two decimals. What does the output imply? Let’s compare RMSE and MAE. The difference between them is RMSE - MAE = 5.14 - 3.26 = 1.88. ‘1.88’ is considered a small number since it is close to 0. Numbers close to 0 indicate that there are no large errors in the forecast. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4adeeb9",
   "metadata": {},
   "source": [
    "## 2.2.4 Creating a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b04416",
   "metadata": {},
   "source": [
    "### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25eb24",
   "metadata": {},
   "source": [
    "### Import & view data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set.\n",
    "df = pd.read_csv('breast_cancer_data.csv', \n",
    "                 index_col='id')\n",
    "\n",
    "# View the DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of null values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the descriptive statistics.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All null values will be dropped.\n",
    "df.drop(labels='Unnamed: 32', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values.\n",
    "df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e231fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if data set is balanced.\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbc0a7",
   "metadata": {},
   "source": [
    "### Create the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages.\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the columns.\n",
    "target_col = 'diagnosis'\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# Set the variables.\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Split the data set into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f237249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary package.\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Create a Decision Tree classifer object.\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=1)\n",
    "\n",
    "# Train the Decision Tree Classifer.\n",
    "dtc = dtc.fit(X, y)\n",
    "\n",
    "# Predict the response for the test data set.\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ae013",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a confusion matrix.\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# View the confusion matrix.\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a81d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same option as with previous models for comparison between models.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d236f08",
   "metadata": {},
   "source": [
    "### Plot the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e43131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Plot the decision tree based on the Gini Index.\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "tree.plot_tree(dtc, fontsize=10)\n",
    "\n",
    "plt.show()\n",
    "#tree.plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d28d8",
   "metadata": {},
   "source": [
    "## 2.2.6 Regression Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef9e43",
   "metadata": {},
   "source": [
    "### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b906d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries:\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as scp\n",
    "import sklearn\n",
    "# Provides classes and functions to estimate many different statistical methods.\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Indicates situations that aren’t necessarily exceptions.\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# Read the provided CSV file/data set.\n",
    "df = pd.read_csv('ecommerce.csv')  \n",
    "\n",
    "# Print a summary of the DataFrame to sense-check it.\n",
    "df.info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746f83b",
   "metadata": {},
   "source": [
    "### Build and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data by indicating all the rows and columns for the Regression Random Forest (RRF):\n",
    "X = df.iloc[:, 0:11].values\n",
    "y = df.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split package:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Import the random forest regressor class:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the regressor object:\n",
    "regressor = RandomForestRegressor(n_estimators=5, \n",
    "                                  random_state=0, \n",
    "                                  n_jobs=2)\n",
    "\n",
    "# Fit the regressor to the data set and predict the y variable:\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Set y_pred.\n",
    "y_pred = regressor.predict(X_test)  \n",
    "\n",
    "# No output means that no errors were found; model was built and fitted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e110731",
   "metadata": {},
   "source": [
    "### Check the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the metrics package.\n",
    "from sklearn import metrics  \n",
    "\n",
    "# Calculate and display the metrics:\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c4964",
   "metadata": {},
   "source": [
    "The output indicates that the MAE is 2.65, the MSE is 20.42, and the RMSE is 4.52 (rounded to two decimals). To understand what this implies, let’s compare RMSE and MAE. The difference between them is RMSE - MAE = 4.52 - 2.65 = 1.87. \n",
    "\n",
    "Just like the 1.88 you determined for the regression decision tree, 1.87 is a relatively small number and indicates that there are no large errors in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b744dc6",
   "metadata": {},
   "source": [
    "## 2.2.7 Creating a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a6608",
   "metadata": {},
   "source": [
    "### Prepare the workstation and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ca749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import data into Python.\n",
    "df = pd.read_csv('breast_cancer_data.csv', \n",
    "                 index_col='id')\n",
    "\n",
    "# View the DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of null values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10591a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine descriptive statistics.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the null values will be dropped.\n",
    "df.drop(labels='Unnamed: 32', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values.\n",
    "df['diagnosis'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the data set is balanced.\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6aa16",
   "metadata": {},
   "source": [
    "### Create a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages.\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Divide data into attributes and labels - all columns.\n",
    "X = df.iloc[:, 0:4].values\n",
    "y = df.iloc[:, 4].values\n",
    "\n",
    "# Set columns.\n",
    "target_col = 'diagnosis'\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# Set variables.\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Create test and train data sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15841bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary package.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a model.\n",
    "forest=RandomForestClassifier(n_estimators=200, criterion='gini', \n",
    "                              min_samples_split=2, min_samples_leaf=2, \n",
    "                              max_features='auto', bootstrap=True, n_jobs=-1, \n",
    "                              random_state=42)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d43a8",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary package.\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6e2da",
   "metadata": {},
   "source": [
    "### Plot the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1,figsize = (4,4), dpi=800)\n",
    "tree.plot_tree(forest.estimators_[0],\n",
    "               filled = True);\n",
    "fig.savefig('rf_individualtree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef032a73",
   "metadata": {},
   "source": [
    "## 2.3.4 Worked Example: K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8632a78",
   "metadata": {},
   "source": [
    "### Prepare the workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data.\n",
    "df = pd.read_csv('fruit.csv')\n",
    "\n",
    "# View the DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293cb0e5",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a89c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_fruit = df.drop(columns=['tree_age', 'location', 'colour_blossom'])\n",
    "\n",
    "# Display a summary of the numeric variables.\n",
    "df_fruit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc8214",
   "metadata": {},
   "source": [
    "### Visualise the Data\n",
    "\n",
    "Visualisations help us to understand what we are working with. For example, are there any visible clusters, correlations and outliers? Let's plot a scatterplot and a pairplot to understand the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seaborn and Matplotlib.\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a scatterplot with Seaborn.\n",
    "sns.scatterplot(x='sepal_length', y='sepal_width',\n",
    "                data=df_fruit, hue='fruit_type')\n",
    "\n",
    "\n",
    "# Create a pairplot with Seaborn.\n",
    "x = df_fruit[['sepal_length', 'sepal_width']]\n",
    "\n",
    "sns.pairplot(df_fruit, vars=x,\n",
    "             hue='fruit_type', diag_kind= 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1552d0",
   "metadata": {},
   "source": [
    "Although there is a lot of data points overlaying, three groups are visible. How can you improve the accuracy or visibility of the three clusters? Let's investigate the elbow and silhouette methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31762a94",
   "metadata": {},
   "source": [
    "### Improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KMeans class.\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# Elbow chart for us to decide on the number of optimal clusters.\n",
    "cs = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n",
    "                    max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x)\n",
    "    cs.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), cs, marker='o')\n",
    "plt.title(\"The Elbow Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"CS\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e02666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try silhouette method\n",
    "\n",
    "# Import silhouette_score class from sklearn.\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Find the range of clusters to be used using silhouette method.\n",
    "sil = []\n",
    "kmax = 10\n",
    "\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans_s = KMeans(n_clusters = k).fit(x)\n",
    "    labels = kmeans_s.labels_\n",
    "    sil.append(silhouette_score(x, labels, metric = 'euclidean'))\n",
    "\n",
    "# Plot the silhouette method.\n",
    "plt.plot(range(2, kmax+1), sil, marker='o')\n",
    "\n",
    "plt.title(\"The Silhouette Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Sil\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb01577",
   "metadata": {},
   "source": [
    "According to the graph, the optimal number of clusters will be four. Let’s investigate whether the accuracy improves, by testing k=3 and k=4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a155ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting k = 4 ie Four clusters\n",
    "\n",
    "# Use 4 clusters:\n",
    "kmeans = KMeans(n_clusters = 4, max_iter = 15000, init='k-means++', random_state=0).fit(x)\n",
    "clusters = kmeans.labels_\n",
    "x['K-Means Predicted'] = clusters\n",
    "\n",
    "# Plot the predicted.\n",
    "sns.pairplot(x, hue='K-Means Predicted', diag_kind= 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308df8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the number of observations per predicted class.\n",
    "\n",
    "# Check the number of observations per predicted class.\n",
    "x['K-Means Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5228cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the clusters\n",
    "# Set plot size.\n",
    "sns.set(rc = {'figure.figsize':(12, 8)})\n",
    "\n",
    "sns.scatterplot(x='sepal_length' , \n",
    "                y ='sepal_width',\n",
    "                data=x , hue='K-Means Predicted',\n",
    "                palette=['red', 'green', 'blue', 'black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying 3 clusters now ie k = 3\n",
    "# Evaluate and fit the model\n",
    "\n",
    "# Use 3 clusters:\n",
    "kmeans = KMeans(n_clusters = 3, max_iter = 15000, init='k-means++', random_state=0).fit(x)\n",
    "clusters = kmeans.labels_\n",
    "x['K-Means Predicted'] = clusters\n",
    "\n",
    "# Plot the predicted.\n",
    "sns.pairplot(x, hue='K-Means Predicted', diag_kind= 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of observations per predicted class.\n",
    "x['K-Means Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the clusters.\n",
    "# Set plot size.\n",
    "sns.set(rc = {'figure.figsize':(12, 8)})\n",
    "\n",
    "sns.scatterplot(x='sepal_length' , \n",
    "                y ='sepal_width',\n",
    "                data=x , hue='K-Means Predicted',\n",
    "                palette=['red', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a598a8",
   "metadata": {},
   "source": [
    "## 2.3.5 Practical Activity: K means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f038b",
   "metadata": {},
   "source": [
    "### Prepare Workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5305c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data into Python.\n",
    "df_ais = pd.read_csv('ais.csv')\n",
    "\n",
    "# View the output.\n",
    "df_ais.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of null values.\n",
    "df_ais.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ac0bc",
   "metadata": {},
   "source": [
    "### Evaluate the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a47780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine descriptive statistics.\n",
    "df_ais.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List column names.\n",
    "df_ais.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745762c",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a93d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seaborn and Matplotlib.\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a scatterplot with Seaborn.\n",
    "sns.scatterplot(x='lbm', y='bmi',\n",
    "                data=df_ais, hue='sex')\n",
    "\n",
    "\n",
    "# Create a pairplot with Seaborn.\n",
    "x = df_ais[['lbm', 'bmi']]\n",
    "\n",
    "sns.pairplot(df_ais, vars=x,\n",
    "             hue='sex', diag_kind= 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77309d66",
   "metadata": {},
   "source": [
    "### Improve Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a75f82",
   "metadata": {},
   "source": [
    "#### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90447c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KMeans class.\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# Elbow chart for us to decide on the number of optimal clusters.\n",
    "cs = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n",
    "                    max_iter = 500, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x)\n",
    "    cs.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), cs, marker='o')\n",
    "plt.title(\"The Elbow Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"CS\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0fe11",
   "metadata": {},
   "source": [
    "#### Silhouette method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import silhouette_score class from sklearn.\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Find the range of clusters to be used using silhouette method.\n",
    "sil = []\n",
    "kmax = 10\n",
    "\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans_s = KMeans(n_clusters = k).fit(x)\n",
    "    labels = kmeans_s.labels_\n",
    "    sil.append(silhouette_score(x, labels, metric = 'euclidean'))\n",
    "\n",
    "# Plot the silhouette method.\n",
    "plt.plot(range(2, kmax+1), sil, marker='o')\n",
    "\n",
    "plt.title(\"The Silhouette Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Sil\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c278503",
   "metadata": {},
   "source": [
    "#### Evaluate and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 5 clusters:\n",
    "kmeans = KMeans(n_clusters = 5, max_iter = 15000, init='k-means++', random_state=0).fit(x)\n",
    "clusters = kmeans.labels_\n",
    "x['K-Means Predicted'] = clusters\n",
    "\n",
    "# Plot the predicted.\n",
    "sns.pairplot(x, hue='K-Means Predicted', diag_kind= 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of observations per predicted class.\n",
    "x['K-Means Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb7b14",
   "metadata": {},
   "source": [
    "### Visualise the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89beb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the K-Means predicted.\n",
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the clusters.\n",
    "# Set plot size.\n",
    "sns.set(rc = {'figure.figsize':(12, 8)})\n",
    "\n",
    "sns.scatterplot(x='bmi' , \n",
    "                y ='lbm',\n",
    "                data=x , hue='K-Means Predicted',\n",
    "                palette=['red', 'green', 'blue', 'black', 'orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ab6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d30d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce28d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edb382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
